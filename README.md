# Machine Learning 2
## 1. Presentation

During the presentation, each member of the group will be asked questions about the project code and project itself as well as general knowledge questions from ML2.

* These questions will be directed to **all group members**, regardless of which part of the project they were officially responsible for.
* Each group member **must be prepared to answer questions on regression and classification**.
* As a result, individual presentation grades may differ depending on each student's ability to answer these questions.

### Group assignments and presentation dates

* We will send you a Doodle link on **2025-10-20 at 9:00** in which you will be able to sign up for the chosen slot.
* There are 4 slots per one time block.

---

## 2. Projects

You need to prepare **two practical machine learning projects in pairs**.

1.  One project on a **regression** problem (tunes 3 algorithms)
2.  One project on a **classification** problem (tunes 3 algorithms)

Each project should be based on a **different dataset**, selected by students and approved by the instructor (e.g., from Kaggle).

### Key Deadlines

* **Approval of final data sets:** Monday, **2025-11-17**, by Moodle.
    * *Data sets not approved - no possibility to submit or to present the project afterwards.*
* **Submission deadline for project:** **2026-01-10**

### How to submit?

Upload to Moodle!

* **Required files:** A single `zip` file named `name_surname_index_1_name_surname_index_2.zip` via Moodle.
* **If file is too big:** Give us a link in Moodle to a GitHub repository.

#### Required files (inside the ZIP):

* PDF with 7-10 slides (presentation)
* PDF with code output for regression
* PDF with code output for classification
* Jupyter Notebook for classification (`.ipynb`) or Python script (`.py`)
* Jupyter Notebook for regression (`.ipynb`) or Python script (`.py`)
* Readme file in `.txt` format

---

## 3. Final Project Evaluation Criteria

* **Reproducibility:** Can the code be run and produce the same results?
* **Originality & Logic:** Is the project idea original and logically developed?
* **Code Comments:** Is the code well-commented and clear?
* **Clarity:** Is the project easy to understand overall?
* **Data & Problem Description:** Is the dataset and problem clearly explained?
* **Model Use & Interpretation:** Are the models appropriately chosen, applied, and interpreted?
* **Summary & Conclusions:** Are they clear and well-supported by results?
* **Structure & Presentation:** Is the project well-structured with appropriate language, tables, and links?
* **Code Correctness:** Is the Python code syntactically and functionally correct?
* **Bibliography:** Are sources cited properly and appropriately?
* **Experimentation:** Did the students explore different models, parameters, or preprocessing techniques and explain why?
* **Error Analysis:** Did they analyze incorrect predictions and try to understand or explain the causes?
* **Ethical Considerations:** Did the project consider ethical aspects (e.g., bias in data, fairness, model misuse)?
* **Data Preprocessing:** Was the data cleaned and prepared appropriately? Were missing values, outliers, or scaling handled?
* **Model Evaluation Metrics:** Were the right evaluation metrics chosen and correctly interpreted (e.g., precision vs recall)?
* **Automation & Reusability:** Is the code modular and reusable (e.g., functions, pipelines, configuration files)?
* **Visualization Quality:** Are visualizations (plots, graphs) clear, labeled, and used to support insights?
* **Structure of the code**
